# Configuration for DCGAN on CelebA
experiment:
  name: dcgan_celeba
  seed: 42
  output_dir: ./outputs/dcgan
  log_interval: 200
  sampling_num: 16
  save_interval: 1000
  num_epochs: 10
  num_workers: 8
  device: cuda

data:
  name: celeba
  batch_size: 128
  image_size: 64
  channels: 3
  crop_size: 108  # CelebA requires center cropping

model:
  name: dcgan
  latent_dim: 100
  ngf: 64  # Number of generator filters
  ndf: 64  # Number of discriminator filters
  use_batch_norm: true

training:
  optimizer: adam
  lr_g: 0.0002
  lr_d: 0.0002
  beta1: 0.5
  beta2: 0.999
  use_scheduler: false

evaluation:
  use_fid: false
  batch_size: 128
  num_samples: 10000
  eval_epoch_interval: 1

inference:
  checkpoint_path: ./outputs/dcgan/checkpoints/final_model.pth
  num_samples: 16

logging:
  use_tensorboard: false
  use_wandb: true
  wandb_project: gans-research

# Tricks for stable training
ema:
  enable: true
  beta: 0.995
  update_after_step: 100
  update_every: 1

label_smoothing:
  enable: true
  smoothing_range: [0.8, 1.2]

random_label_flip:
  enable: true
  prob: 0.2

augment:
  enable: true
  policy: "color,translation"